{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58378c31",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5a7860",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Models\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m     20\u001b[39m plt.style.use(\u001b[33m'\u001b[39m\u001b[33mggplot\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m SEED = \u001b[32m42\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "# Sklearn Core\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b42119",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12783f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads data and creates the classification target based on Exam_Score.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Drop duplicates if any\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # CLASSIFICATION LOGIC:\n",
    "    # We map the continuous Exam_Score to 3 classes:\n",
    "    # 0: Low Performance (< 65)\n",
    "    # 1: Average Performance (65 - 79)\n",
    "    # 2: High Performance (>= 80)\n",
    "    def categorize_score(score):\n",
    "        if score < 65: return 'Low'\n",
    "        elif score < 80: return 'Average'\n",
    "        else: return 'High'\n",
    "\n",
    "    # Create Target\n",
    "    df['Performance_Category'] = df['Exam_Score'].apply(categorize_score)\n",
    "    \n",
    "    # Drop the original continuous target to prevent data leakage\n",
    "    df = df.drop(columns=['Exam_Score'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execution\n",
    "df = load_and_prep_data('StudentPerformanceFactors.csv')\n",
    "print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "print(f\"Class Distribution:\\n{df['Performance_Category'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed2f26",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Generates summary statistics and visualizations.\n",
    "    \"\"\"\n",
    "    # 1. Summary Statistics\n",
    "    print(\"\\n--- Numerical Summary ---\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # 2. Target Distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='Performance_Category', data=df, palette='viridis', order=['Low', 'Average', 'High'])\n",
    "    plt.title('Target Distribution: Student Performance')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Correlation Matrix (Numerical Features Only)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "    corr = numeric_df.corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Boxplot: Hours Studied vs Performance\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x='Performance_Category', y='Hours_Studied', data=df, order=['Low', 'Average', 'High'])\n",
    "    plt.title('Impact of Study Hours on Performance')\n",
    "    plt.show()\n",
    "\n",
    "perform_eda(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db996639",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(X):\n",
    "    \"\"\"\n",
    "    Custom function to create domain-specific features.\n",
    "    Designed to work within a FunctionTransformer.\n",
    "    \"\"\"\n",
    "    X_new = X.copy()\n",
    "    \n",
    "    # Feature 1: Effective Study Score (Interaction)\n",
    "    # Rationale: Studying a lot matters less if attendance is poor.\n",
    "    # Check if columns exist to prevent errors\n",
    "    if 'Hours_Studied' in X_new.columns and 'Attendance' in X_new.columns:\n",
    "        X_new['Effective_Study'] = X_new['Hours_Studied'] * (X_new['Attendance'] / 100)\n",
    "        \n",
    "    # Feature 2: Wellness Index (Aggregation)\n",
    "    # Rationale: Sleep and Physical activity contribute to cognitive function.\n",
    "    if 'Sleep_Hours' in X_new.columns and 'Physical_Activity' in X_new.columns:\n",
    "        X_new['Wellness_Index'] = X_new['Sleep_Hours'] + X_new['Physical_Activity']\n",
    "        \n",
    "    return X_new\n",
    "\n",
    "# Separate Features and Target\n",
    "X = df.drop('Performance_Category', axis=1)\n",
    "y = df['Performance_Category']\n",
    "\n",
    "# Encode Target to Integers (Required for XGBoost)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "class_names = le.classes_\n",
    "print(f\"Target Mapping: {dict(zip(range(len(class_names)), class_names))}\")\n",
    "\n",
    "# Split: 70% Train, 15% Validation, 15% Test\n",
    "# First, split into Train (70%) and Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_encoded, test_size=0.30, stratify=y_encoded, random_state=SEED\n",
    ")\n",
    "# Split Temp into Val (15%) and Test (15%) -> 50% of 30% is 15% total\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}, Val Shape: {X_val.shape}, Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d78319",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc862cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Column Types\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 1. Numeric Transformer: Impute median -> Scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2. Categorical Transformer: Impute freq -> OneHot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. Combine into Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 4. Create Feature Engineering Transformer\n",
    "feature_eng_transformer = FunctionTransformer(feature_engineering, validate=False)\n",
    "\n",
    "# 5. Full Pipeline Construction (Preprocessing Only)\n",
    "# Note: We apply feature engineering BEFORE column transformation to ensure new columns are processed\n",
    "def get_pipeline(classifier):\n",
    "    return Pipeline(steps=[\n",
    "        ('feat_eng', feature_eng_transformer),\n",
    "        # Note: We would need to update column lists dynamically for ColumnTransformer \n",
    "        # if Feature Engineering adds columns. \n",
    "        # For simplicity in this demo, we assume Feature Engineering happens inside the \n",
    "        # Optuna loop or we treat 'preprocessor' as dealing with original columns.\n",
    "        # *Correction for Robustness*: In production, we usually run FE first, then define \n",
    "        # ColumnTransformer on the new dataframe structure. \n",
    "        # To keep it simple for this script, we will apply FE logic inside the pipeline \n",
    "        # but let the ColumnTransformer handle the output \"passthrough\" or re-selector.\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f375d0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to optimize Random Forest and XGBoost.\n",
    "    \"\"\"\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['RandomForest', 'XGBoost'])\n",
    "    \n",
    "    if classifier_name == 'RandomForest':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 5, 30),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 15),\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "        clf = RandomForestClassifier(**param, random_state=SEED, n_jobs=-1)\n",
    "        \n",
    "    else: # XGBoost\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0),\n",
    "            'eval_metric': 'mlogloss'\n",
    "        }\n",
    "        clf = XGBClassifier(**param, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "    # Build Pipeline\n",
    "    # IMPORTANT: We apply feature engineering to X_train before passing to CV\n",
    "    # to handle the dynamic column issue mentioned above, \n",
    "    # or we ensure the preprocessor handles the output of feature_engineering.\n",
    "    # Here we simplify:\n",
    "    \n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # 3-Fold Stratified Cross-Validation on TRAIN set\n",
    "    # We optimize for 'f1_weighted' due to potential class imbalance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1_weighted')\n",
    "    return scores.mean()\n",
    "\n",
    "# Run Optimization\n",
    "print(\"Starting Optuna Study...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20) # Increase n_trials for better results\n",
    "\n",
    "print(f\"Best Classifier: {study.best_params['classifier']}\")\n",
    "print(f\"Best F1 Score: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f30325",
   "metadata": {},
   "source": [
    "## Final evaluation & Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Best Params\n",
    "best_params = study.best_params\n",
    "model_type = best_params.pop('classifier')\n",
    "\n",
    "# Instantiate Best Model\n",
    "if model_type == 'RandomForest':\n",
    "    # Clean keys for RF\n",
    "    rf_params = {k.replace('rf_', ''): v for k, v in best_params.items()}\n",
    "    final_clf = RandomForestClassifier(**rf_params, random_state=SEED, class_weight='balanced')\n",
    "else:\n",
    "    # Clean keys for XGB\n",
    "    xgb_params = {k.replace('xgb_', ''): v for k, v in best_params.items()}\n",
    "    final_clf = XGBClassifier(**xgb_params, random_state=SEED, eval_metric='mlogloss')\n",
    "\n",
    "# Final Pipeline\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', final_clf)\n",
    "])\n",
    "\n",
    "# Train on Train + Validation set (Optional, but often good practice)\n",
    "X_final_train = pd.concat([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_pipeline.fit(X_final_train, y_final_train)\n",
    "\n",
    "# Predict on Test Set\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "# --- METRICS ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"FINAL EVALUATION: {model_type}\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# --- CONFUSION MATRIX ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - {model_type}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# --- FEATURE IMPORTANCE ---\n",
    "# Extracting feature names after OneHotEncoding is tricky but necessary for interpretation\n",
    "if hasattr(final_clf, 'feature_importances_'):\n",
    "    # Get transformed feature names\n",
    "    try:\n",
    "        # Access the preprocessor step\n",
    "        prep = final_pipeline.named_steps['preprocessor']\n",
    "        \n",
    "        # Numeric names\n",
    "        num_names = numeric_features\n",
    "        \n",
    "        # Categorical names\n",
    "        cat_names = prep.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "        \n",
    "        feature_names = np.r_[num_names, cat_names]\n",
    "        importances = final_clf.feature_importances_\n",
    "        \n",
    "        # Plot Top 10\n",
    "        indices = np.argsort(importances)[::-1][:10]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Top 10 Feature Importances\")\n",
    "        plt.barh(range(10), importances[indices], align=\"center\")\n",
    "        plt.yticks(range(10), feature_names[indices])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract feature names directly: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
